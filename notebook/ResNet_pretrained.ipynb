{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision tqdm pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import ResNet101_Weights, resnet101\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root, batch_size=32):\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    data_augmentation = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size=(224, 224), antialias=True),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.7037, 0.6818, 0.6685], [0.2739, 0.2798, 0.2861]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ImageFolder\n",
    "    train_set = ImageFolder(\n",
    "        f\"{root}/train\", transform=transforms.Compose([data_augmentation, preprocess])\n",
    "    )\n",
    "    valid_set = ImageFolder(f\"{root}/val\", transform=preprocess)\n",
    "    test_set = ImageFolder(f\"{root}/test\", transform=preprocess)\n",
    "\n",
    "    # DataLoader\n",
    "    dataloader = {\n",
    "        \"train\": DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "        \"valid\": DataLoader(valid_set, batch_size=batch_size, shuffle=False),\n",
    "        \"test\": DataLoader(test_set, batch_size=batch_size, shuffle=False),\n",
    "    }\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    num_epochs=20,\n",
    "    load_path=\"./pretrained\",\n",
    "    save_path=\"./results\",\n",
    "    lr=0.001,\n",
    "    momentum=0.9,\n",
    "    resume=False,\n",
    "):\n",
    "    torch.manual_seed(42)\n",
    "    os.makedirs(\"./results\", exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    best_acc = 0.0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    results = []\n",
    "    start_epoch = 0\n",
    "    if resume:\n",
    "        df = pd.read_csv(f\"{load_path}/results.csv\")\n",
    "        results = list(df.T.to_dict().values())\n",
    "        start_epoch = int(results[-1][\"epoch\"])\n",
    "\n",
    "        checkpoint = torch.load(\n",
    "            f\"{load_path}/resnet_{start_epoch}.pth\", weights_only=True\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "\n",
    "        for _ in range(start_epoch):\n",
    "            for _ in dataloader[\"train\"]:\n",
    "                break\n",
    "\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "    print(\"Start training with\", str(device).upper())\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        df_row = {\"epoch\": epoch + 1}\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            with tqdm(\n",
    "                total=len(dataloader[phase]),\n",
    "                desc=f\"{phase.capitalize()} epoch {epoch+1}/{num_epochs}\",\n",
    "                unit=\"bat\",\n",
    "            ) as pbar:\n",
    "                for inputs, labels in dataloader[phase]:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicts = torch.max(outputs.data, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    running_corrects += torch.sum(predicts == labels.data)\n",
    "\n",
    "                    pbar.update()\n",
    "\n",
    "                epoch_loss = running_loss / len(dataloader[phase])\n",
    "                epoch_acc = 100 * running_corrects / len(dataloader[phase].dataset)\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"loss\": f\"{epoch_loss:.4f}\",\n",
    "                        \"acc\": f\"{epoch_acc:.2f}\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                df_row[f\"{phase}_loss\"] = epoch_loss\n",
    "                df_row[f\"{phase}_acc\"] = epoch_acc\n",
    "\n",
    "                if phase == \"valid\" and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "\n",
    "                    torch.save(\n",
    "                        {\n",
    "                            \"model\": model.state_dict(),\n",
    "                            \"optimizer\": optimizer.state_dict(),\n",
    "                            \"scheduler\": scheduler.state_dict(),\n",
    "                        },\n",
    "                        f\"{save_path}/resnet_{epoch+1}.pth\",\n",
    "                    )\n",
    "\n",
    "        scheduler.step()\n",
    "        results.append(df_row)\n",
    "        pd.DataFrame(results).to_csv(f\"{save_path}/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, test_loader: DataLoader, weights_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    weights = torch.load(weights_path, weights_only=True)\n",
    "    model.load_state_dict(weights[\"model\"])\n",
    "\n",
    "    correct = 0\n",
    "    with tqdm(total=len(test_loader), desc=\"Test\", unit=\"bat\") as pbar:\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicts = torch.max(outputs.data, 1)\n",
    "                correct += (predicts == labels).sum().item()\n",
    "                pbar.update()\n",
    "\n",
    "    accuracy = 100 * correct / len(test_loader.dataset)\n",
    "    print(f\"Test accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(num_classes=10):\n",
    "    model = resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(in_features=model.fc.in_features, out_features=256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(in_features=256, out_features=num_classes, bias=False),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = load_dataset(\"/kaggle/input/categories-classification/data\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(model, dataloader, num_epochs=20, resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, dataloader[\"test\"], \"./results/resnet_20.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
